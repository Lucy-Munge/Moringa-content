{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Multiple Regression Model Evaluation"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Introduction\n", "\n", "Multiple regression models, like simple regression models, can be evaluated using R-Squared (coefficient of determination) for measuring the amount of explained variance, and the F-statistic for determining statistical significance. You also may want to consider using other metrics, including adjusted R-Squared and error-based metrics such as MAE and RMSE. Each metric provides slightly different information, so you will need additional information from stakeholders in order to choose the most appropriate one(s)."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Objectives\n", "\n", "You will be able to:\n", "\n", "* Measure multiple linear regression model performance using adjusted R-Squared\n", "* Measure regression model performance using error-based metrics"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Multiple Regression Model with Auto-MPG Dataset\n", "\n", "In the cell below we load the Auto MPG dataset and build a StatsModels multiple regression model that uses the `weight` and `model year` attributes to predict the `mpg` attribute."]}, {"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [], "source": ["import pandas as pd\n", "import statsmodels.api as sm"]}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [{"data": {"text/html": ["<div>\n", "<style scoped>\n", "    .dataframe tbody tr th:only-of-type {\n", "        vertical-align: middle;\n", "    }\n", "\n", "    .dataframe tbody tr th {\n", "        vertical-align: top;\n", "    }\n", "\n", "    .dataframe thead th {\n", "        text-align: right;\n", "    }\n", "</style>\n", "<table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", "    <tr style=\"text-align: right;\">\n", "      <th></th>\n", "      <th>mpg</th>\n", "      <th>cylinders</th>\n", "      <th>displacement</th>\n", "      <th>horsepower</th>\n", "      <th>weight</th>\n", "      <th>acceleration</th>\n", "      <th>model year</th>\n", "      <th>origin</th>\n", "      <th>car name</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <th>0</th>\n", "      <td>18.0</td>\n", "      <td>8</td>\n", "      <td>307.0</td>\n", "      <td>130</td>\n", "      <td>3504</td>\n", "      <td>12.0</td>\n", "      <td>70</td>\n", "      <td>1</td>\n", "      <td>chevrolet chevelle malibu</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1</th>\n", "      <td>15.0</td>\n", "      <td>8</td>\n", "      <td>350.0</td>\n", "      <td>165</td>\n", "      <td>3693</td>\n", "      <td>11.5</td>\n", "      <td>70</td>\n", "      <td>1</td>\n", "      <td>buick skylark 320</td>\n", "    </tr>\n", "    <tr>\n", "      <th>2</th>\n", "      <td>18.0</td>\n", "      <td>8</td>\n", "      <td>318.0</td>\n", "      <td>150</td>\n", "      <td>3436</td>\n", "      <td>11.0</td>\n", "      <td>70</td>\n", "      <td>1</td>\n", "      <td>plymouth satellite</td>\n", "    </tr>\n", "    <tr>\n", "      <th>3</th>\n", "      <td>16.0</td>\n", "      <td>8</td>\n", "      <td>304.0</td>\n", "      <td>150</td>\n", "      <td>3433</td>\n", "      <td>12.0</td>\n", "      <td>70</td>\n", "      <td>1</td>\n", "      <td>amc rebel sst</td>\n", "    </tr>\n", "    <tr>\n", "      <th>4</th>\n", "      <td>17.0</td>\n", "      <td>8</td>\n", "      <td>302.0</td>\n", "      <td>140</td>\n", "      <td>3449</td>\n", "      <td>10.5</td>\n", "      <td>70</td>\n", "      <td>1</td>\n", "      <td>ford torino</td>\n", "    </tr>\n", "    <tr>\n", "      <th>...</th>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "    </tr>\n", "    <tr>\n", "      <th>387</th>\n", "      <td>27.0</td>\n", "      <td>4</td>\n", "      <td>140.0</td>\n", "      <td>86</td>\n", "      <td>2790</td>\n", "      <td>15.6</td>\n", "      <td>82</td>\n", "      <td>1</td>\n", "      <td>ford mustang gl</td>\n", "    </tr>\n", "    <tr>\n", "      <th>388</th>\n", "      <td>44.0</td>\n", "      <td>4</td>\n", "      <td>97.0</td>\n", "      <td>52</td>\n", "      <td>2130</td>\n", "      <td>24.6</td>\n", "      <td>82</td>\n", "      <td>2</td>\n", "      <td>vw pickup</td>\n", "    </tr>\n", "    <tr>\n", "      <th>389</th>\n", "      <td>32.0</td>\n", "      <td>4</td>\n", "      <td>135.0</td>\n", "      <td>84</td>\n", "      <td>2295</td>\n", "      <td>11.6</td>\n", "      <td>82</td>\n", "      <td>1</td>\n", "      <td>dodge rampage</td>\n", "    </tr>\n", "    <tr>\n", "      <th>390</th>\n", "      <td>28.0</td>\n", "      <td>4</td>\n", "      <td>120.0</td>\n", "      <td>79</td>\n", "      <td>2625</td>\n", "      <td>18.6</td>\n", "      <td>82</td>\n", "      <td>1</td>\n", "      <td>ford ranger</td>\n", "    </tr>\n", "    <tr>\n", "      <th>391</th>\n", "      <td>31.0</td>\n", "      <td>4</td>\n", "      <td>119.0</td>\n", "      <td>82</td>\n", "      <td>2720</td>\n", "      <td>19.4</td>\n", "      <td>82</td>\n", "      <td>1</td>\n", "      <td>chevy s-10</td>\n", "    </tr>\n", "  </tbody>\n", "</table>\n", "<p>392 rows \u00d7 9 columns</p>\n", "</div>"], "text/plain": ["      mpg  cylinders  displacement  horsepower  weight  acceleration  \\\n", "0    18.0          8         307.0         130    3504          12.0   \n", "1    15.0          8         350.0         165    3693          11.5   \n", "2    18.0          8         318.0         150    3436          11.0   \n", "3    16.0          8         304.0         150    3433          12.0   \n", "4    17.0          8         302.0         140    3449          10.5   \n", "..    ...        ...           ...         ...     ...           ...   \n", "387  27.0          4         140.0          86    2790          15.6   \n", "388  44.0          4          97.0          52    2130          24.6   \n", "389  32.0          4         135.0          84    2295          11.6   \n", "390  28.0          4         120.0          79    2625          18.6   \n", "391  31.0          4         119.0          82    2720          19.4   \n", "\n", "     model year  origin                   car name  \n", "0            70       1  chevrolet chevelle malibu  \n", "1            70       1          buick skylark 320  \n", "2            70       1         plymouth satellite  \n", "3            70       1              amc rebel sst  \n", "4            70       1                ford torino  \n", "..          ...     ...                        ...  \n", "387          82       1            ford mustang gl  \n", "388          82       2                  vw pickup  \n", "389          82       1              dodge rampage  \n", "390          82       1                ford ranger  \n", "391          82       1                 chevy s-10  \n", "\n", "[392 rows x 9 columns]"]}, "execution_count": 2, "metadata": {}, "output_type": "execute_result"}], "source": ["data = pd.read_csv(\"auto-mpg.csv\")\n", "data"]}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [], "source": ["y = data[\"mpg\"]\n", "X = data[[\"weight\", \"model year\"]]"]}, {"cell_type": "code", "execution_count": 4, "metadata": {}, "outputs": [], "source": ["model = sm.OLS(y, sm.add_constant(X))\n", "results = model.fit()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Reviewing F-Statistic and R-Squared\n", "\n", "First, we can check the model's F-statistic and F-statistic p-value to see if the model was statistically significant overall:"]}, {"cell_type": "code", "execution_count": 5, "metadata": {}, "outputs": [{"data": {"text/plain": ["(819.4730484488967, 3.3321631451383913e-140)"]}, "execution_count": 5, "metadata": {}, "output_type": "execute_result"}], "source": ["results.fvalue, results.f_pvalue"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Based on this very small p-value, we can say that the model is statistically significant.\n", "\n", "We can also check the R-Squared (coefficient of determination):"]}, {"cell_type": "code", "execution_count": 6, "metadata": {}, "outputs": [{"data": {"text/plain": ["0.8081803058793997"]}, "execution_count": 6, "metadata": {}, "output_type": "execute_result"}], "source": ["results.rsquared"]}, {"cell_type": "markdown", "metadata": {}, "source": ["This means that our model is explaining about 81% of the variance in `mpg`."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Limitations of R-Squared\n", "\n", "R-Squared is conventionally the \"to-go\" measurement for overall model performance, but it has some drawbacks.\n", "\n", "First, as we add more predictors, R-Squared is only going to increase. More predictors allow the model an extra degree of freedom in trying to approximate a target. But this doesn't necessarily mean we have a better model, since we're likely to start seeing coefficients that are unstable and potentially not statistically significant. (We'll also see that these models might violate some of the _assumptions_ of linear regression, which we'll describe in more detail later.)\n", "\n", "To address this issue, consider using **adjusted R-Squared**. This version of R-Squared includes a correction for the number of predictors used.\n", "\n", "Second, \"proportion of variance explained\" may not be the best way to describe your model's performance. It is very sensitive to the variance in the available data, where a very small variance in the predictors can lead to a small R-Squared and a very large variance in the predictors can lead to a large R-Squared, regardless of how well the model actually describes the true relationship between the variables. It can also be challenging to use when communicating with non-technical stakeholders who are less likely to have an understanding of \"variance\".\n", "\n", "To address this issue, consider using an **error-based metric**. These measure the performance in terms of the errors (residuals), using various techniques to aggregate and summarize them."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Adjusted R-Squared\n", "\n", "Adjusted R-Squared is still following the fundamental concept of \"proportion of variance explained\", except that the numerator and denominator are adjusted based on the degrees of freedom for the residuals\n", "\n", "Recall that this is the formula for R-Squared:\n", "\n", "$$ \\large{ R^2 = \\frac{ESS}{TSS} = \\frac{\\sum_i{(\\hat{y_i} - \\bar{y_i})^2}}{\\sum_i(y_i - \\bar{y_i})^2}} $$\n", "\n", "and that we can rewrite this to be:\n", "\n", "$$ \\large{ R^2 = 1 - \\frac{RSS}{TSS} = 1 - \\frac{\\sum_i(y_i - \\hat{y_i})^2}{\\sum_i(y_i - \\bar{y_i})^2}} $$\n", "\n", "Adjusted R-Squared, also written $\\bar{R^2}$, takes the $RSS$ value and divides it by the degrees of freedom of the residuals, and takes the $TSS$ value and divides it by the degrees of freedom of the total.\n", "\n", "$$ \\large{ \\bar{R^2} = 1 - \\frac{RSS / df_{resid}}{TSS / df_{total}} = 1 - \\frac{(RSS)}{(TSS)} \\frac{(df_{total})}{(df_{resid})}} $$\n", "\n", "We can calculate it ourselves like this:"]}, {"cell_type": "code", "execution_count": 7, "metadata": {}, "outputs": [{"data": {"text/plain": ["4568.952041558536"]}, "execution_count": 7, "metadata": {}, "output_type": "execute_result"}], "source": ["y_pred = results.predict(sm.add_constant(X)) # use fitted model to generate predictions for y\n", "rss = ((y_pred - y) ** 2).sum()\n", "rss"]}, {"cell_type": "code", "execution_count": 8, "metadata": {}, "outputs": [{"data": {"text/plain": ["23818.99346938776"]}, "execution_count": 8, "metadata": {}, "output_type": "execute_result"}], "source": ["intercept_only_line = pd.Series([y.mean() for x in range(len(y))])\n", "tss = ((y - intercept_only_line) ** 2).sum()\n", "tss"]}, {"cell_type": "code", "execution_count": 9, "metadata": {}, "outputs": [{"data": {"text/plain": ["389"]}, "execution_count": 9, "metadata": {}, "output_type": "execute_result"}], "source": ["df_resid = len(y) - sm.add_constant(X).shape[1] # num observations - num parameters (including constant)\n", "df_resid"]}, {"cell_type": "code", "execution_count": 10, "metadata": {}, "outputs": [{"data": {"text/plain": ["391"]}, "execution_count": 10, "metadata": {}, "output_type": "execute_result"}], "source": ["df_tot = len(y) - 1 # number observations - 1\n", "df_tot"]}, {"cell_type": "code", "execution_count": 11, "metadata": {}, "outputs": [{"data": {"text/plain": ["0.8071940863723529"]}, "execution_count": 11, "metadata": {}, "output_type": "execute_result"}], "source": ["1 - (rss / tss) * (df_tot / df_resid)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["If we already have the value of R-Squared, we can also calculate it like this:\n", "\n", "$$ \\large{ \\bar{R^2} = 1 - (1 - R^2) \\frac{df_{total}}{df_{resid}}} $$"]}, {"cell_type": "code", "execution_count": 12, "metadata": {}, "outputs": [{"data": {"text/plain": ["0.8071940863723529"]}, "execution_count": 12, "metadata": {}, "output_type": "execute_result"}], "source": ["1 - (1 - results.rsquared) * (df_tot / df_resid)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["...but actually we don't have to do either of those things, because **StatsModels will also calculate adjusted R-Squared for us**!"]}, {"cell_type": "code", "execution_count": 13, "metadata": {}, "outputs": [{"data": {"text/plain": ["0.8071940863723529"]}, "execution_count": 13, "metadata": {}, "output_type": "execute_result"}], "source": ["results.rsquared_adj"]}, {"cell_type": "markdown", "metadata": {}, "source": ["If you compare this to the non-adjusted version of R-Squared, you'll see that it is fairly similar."]}, {"cell_type": "code", "execution_count": 14, "metadata": {}, "outputs": [{"data": {"text/plain": ["0.8081803058793997"]}, "execution_count": 14, "metadata": {}, "output_type": "execute_result"}], "source": ["results.rsquared"]}, {"cell_type": "markdown", "metadata": {}, "source": ["However we typically prefer using adjusted R-Squared if we're doing multiple regression modeling because adjusted R-Squared essentially only increases when the increase in variance explained is more than what we would expect to see due to chance."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Error-Based Metrics\n", "\n", "Some issues with R-Squared can't be addressed with small tweaks like adjusted R-Squared. [This lecture that went viral on Reddit in 2015](https://www.stat.cmu.edu/~cshalizi/mreg/15/lectures/10/lecture-10.pdf), for example, argues that R-Squared is \"useless\". We won't go that far, but there are some cases where an \"error-based\" metric would be more appropriate than R-Squared.\n", "\n", "While R-Squared is a ***relative*** metric that compares the variance explained by the model to the variance explained by an intercept-only \"baseline\" model, most error-based metrics are ***absolute*** metrics that describe some form of average error.\n", "\n", "(Technically R-Squared is also based on errors, but it's more indirect, so when we refer to \"error-based\" metrics we mean those that are more directly measuring average error.)\n", "\n", "### Why Not Just Sum the Residuals?\n", "\n", "If we just find the sum of the residuals and divide it by the number of observations, we will get a very tiny value, like this:"]}, {"cell_type": "code", "execution_count": 15, "metadata": {}, "outputs": [{"data": {"text/plain": ["2.878423123436324e-14"]}, "execution_count": 15, "metadata": {}, "output_type": "execute_result"}], "source": ["results.resid.sum() / len(y)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["This is because the residuals are a combination of positive and negative values."]}, {"cell_type": "code", "execution_count": 16, "metadata": {}, "outputs": [{"data": {"text/plain": ["0       2.573765\n", "1       0.827227\n", "2       2.122784\n", "3       0.102888\n", "4       1.209001\n", "         ...    \n", "387    -2.249356\n", "388    10.373474\n", "389    -0.532233\n", "390    -2.343648\n", "391     1.286399\n", "Length: 392, dtype: float64"]}, "execution_count": 16, "metadata": {}, "output_type": "execute_result"}], "source": ["results.resid"]}, {"cell_type": "markdown", "metadata": {}, "source": ["When you add a positive residual value (where the model predicted a value that was too low) and a negative residual (where the model predicted a value that was too high), these \"cancel each other out\". But from our perspective, both of those were errors, and both should be counted. If we want this to happen, we need to transform them in some way."]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Mean Absolute Error\n", "\n", "***Mean absolute error (MAE)*** calculates the **absolute value** of each error before adding it to the sum. We can just use the `.abs()` method on the residuals series to do this:"]}, {"cell_type": "code", "execution_count": 17, "metadata": {}, "outputs": [{"data": {"text/plain": ["0       2.573765\n", "1       0.827227\n", "2       2.122784\n", "3       0.102888\n", "4       1.209001\n", "         ...    \n", "387     2.249356\n", "388    10.373474\n", "389     0.532233\n", "390     2.343648\n", "391     1.286399\n", "Length: 392, dtype: float64"]}, "execution_count": 17, "metadata": {}, "output_type": "execute_result"}], "source": ["results.resid.abs()"]}, {"cell_type": "code", "execution_count": 18, "metadata": {}, "outputs": [{"data": {"text/plain": ["2.608011858238716"]}, "execution_count": 18, "metadata": {}, "output_type": "execute_result"}], "source": ["mae = results.resid.abs().sum() / len(y)\n", "mae"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### MAE Interpretation\n", "\n", "Unlike R-Squared, the units of MAE are in the units of $y$. Our target variable is `mpg`, so this result is in miles per gallon.\n", "\n", "For this specific MAE value, it means that ***our model is off by about 2.6 miles per gallon in a given prediction***.\n", "\n", "Is this a \"good\" MAE? In general, a lower MAE is better, and the smallest theoretically possible MAE is 0.\n", "\n", "Your MAE will use the same units as the target, so a \"good\" MAE varies accordingly. For example, an MAE of 100 would be pretty bad if the target is the fuel economy of a car in MPG, but an MAE of 100 would be excellent if the target is the price of a house in USD.\n", "\n", "Like with any other metric, you would need more context from stakeholders to be able to answer this question more precisely."]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Root Mean Squared Error\n", "\n", "Another popular error-based metric is root mean squared error. ***Root mean squared error (RMSE)*** calculates the **squared** value of each error, sums them, then takes the **square root** at the end.\n", "\n", "We can use broadcasting with `**` (since $\\sqrt{x}$ is the same as $x^{0.5}$) to calculate this:"]}, {"cell_type": "code", "execution_count": 19, "metadata": {}, "outputs": [{"data": {"text/plain": ["0        6.624267\n", "1        0.684305\n", "2        4.506212\n", "3        0.010586\n", "4        1.461683\n", "          ...    \n", "387      5.059602\n", "388    107.608970\n", "389      0.283272\n", "390      5.492688\n", "391      1.654822\n", "Length: 392, dtype: float64"]}, "execution_count": 19, "metadata": {}, "output_type": "execute_result"}], "source": ["results.resid ** 2"]}, {"cell_type": "code", "execution_count": 20, "metadata": {}, "outputs": [{"data": {"text/plain": ["3.414013752452535"]}, "execution_count": 20, "metadata": {}, "output_type": "execute_result"}], "source": ["rmse = ((results.resid ** 2).sum() / len(y)) ** 0.5\n", "rmse"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Root Mean Squared Error Interpretation\n", "\n", "Even though the formula is different from MAE, the RMSE value is conventionally interpreted the same way.\n", "\n", "For this specific RMSE value, it means that ***our model is off by about 3.4 miles per gallon in a given prediction***."]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Comparing MAE and RMSE\n", "\n", "Since both of these metrics express error in the same units, how do you know which one to choose?\n", "\n", "The main question to consider is whether linearly increasing errors should be seen as ***linearly*** worse or ***exponentially*** worse. Consider the comparison of an error of 1 vs. an error of 10. Clearly an error of 10 is worse, but how much worse is it? If 10 is 10x worse than 1, that means MAE is a good metric. If 10 is 100x worse than 1, that means RMSE is a good metric.\n", "\n", "There are also contexts related to _gradient descent_ where RMSE is more mathematically appropriate, which become relevant when we move beyond models with \"closed-form\" solutions like ordinary least squares."]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Calculating Metrics with Scikit-Learn\n", "\n", "Rather than performing the math yourself to calculate MAE or RMSE, you can import functions from scikit-learn to make the task a bit easier."]}, {"cell_type": "code", "execution_count": 21, "metadata": {}, "outputs": [], "source": ["from sklearn.metrics import mean_absolute_error, mean_squared_error"]}, {"cell_type": "markdown", "metadata": {}, "source": ["`mean_absolute_error` ([documentation here](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html)) is very straightforward to use for calculating MAE. You pass in the true $y$ values along with the predicted $\\hat{y}$ values, and it returns a score."]}, {"cell_type": "code", "execution_count": 22, "metadata": {}, "outputs": [{"data": {"text/plain": ["2.608011858238716"]}, "execution_count": 22, "metadata": {}, "output_type": "execute_result"}], "source": ["mean_absolute_error(y, y_pred)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["`mean_squared_error` ([documentation here](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html)) is a bit more complicated to use for calculating RMSE. In addition to passing in $y$ and $\\hat{y}$, you need to specify `squared=False` to get RMSE. If you skip that third argument (or pass in `True` rather than `False`), you'll get MSE (mean squared error, without taking the square root at the end), which is useful in some machine learning contexts but challenging to describe to a stakeholder."]}, {"cell_type": "code", "execution_count": 23, "metadata": {}, "outputs": [{"data": {"text/plain": ["3.414013752452535"]}, "execution_count": 23, "metadata": {}, "output_type": "execute_result"}], "source": ["mean_squared_error(y, y_pred, squared=False)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Summary\n", "\n", "In this lesson you learned about some additional ways to evaluate regression model performance: adjusted R-Squared and error-based metrics. Adjusted R-Squared, like R-Squared, measures the percentage of variance explained, but it is adjusted to account for additional predictors being added. You can get the adjusted R-Squared value by using the `rsquared_adj` attribute of the StatsModels summary. Error-based metrics, such as MAE and RMSE, summarize the average errors made by the model, rather than the variance explained. You can calculate them using functions imported from scikit-learn."]}], "metadata": {"kernelspec": {"display_name": "Python (learn-env)", "language": "python", "name": "learn-env"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.5"}}, "nbformat": 4, "nbformat_minor": 4}