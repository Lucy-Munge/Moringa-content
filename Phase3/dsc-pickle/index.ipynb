{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Pickle\n", "\n", "## Introduction\n", "\n", "Pickle is an invaluable tool for saving objects.  In this lesson you will learn how to use it on various different Python data types.\n", "\n", "## Objectives\n", "\n", "You will be able to:\n", "\n", "* Describe the circumstances in which you would want to use a pickle file\n", "* Write a pickle file\n", "* Read a pickle file\n", "* Use the `joblib` library to pickle and load a scikit-learn class"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Data Serialization\n", "\n", "Think about the importance of being able to save data files to CSV, or another format. For example, you start with a raw dataset which you may have downloaded from the web. Then you painstakingly take hours preprocessing the data, cleaning it, constructing features, aggregates, and other views. In order to avoid having to rerun your entire process, you are apt to save the current final cleaned version of the dataset into a serialized format like CSV.\n", "\n", "`pickle` allows you to go beyond just storing data in a format like CSV, and save any object that is currently loaded into your Python interpreter. Literally anything. You could save data stored in a `dict`, `list`, or `set` as a pickle file. You can also save functions or class instances as pickle files. Saving models is one of the important use cases of this technique."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Pickling Base Python Objects\n", "\n", "Let's say we have this nested data structure example (from the [Python docs](https://docs.python.org/3/library/pickle.html#examples)), which would not be suitable for storage as a CSV because the values are different data types:"]}, {"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [], "source": ["data_object = {\n", "    'a': [1, 2.0, 3, 4+6j],\n", "    'b': ('character string', b'byte string'),\n", "    'c': {None, True, False}\n", "}"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Importing `pickle`\n", "\n", "`pickle` is a module built in to Python that is suitable for pickling base Python objects. You can import it like this:"]}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [], "source": ["import pickle"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Writing Objects to Pickle\n", "\n", "Let's store this object as a file on disk called `data.pickle`.\n", "\n", "1. Open a file called `'data.pickle'`.\n", "   1. The `.pickle` file extension is conventional for Python 3 objects. You can use a different file name or extension and it won't make a difference as far as Python is concerned, but we recommend using `.pickle` so it's clear what the file is\n", "2. We'll need to open the file using mode `'wb'`.\n", "   1. `w` because we want to write data to the file (and automatically create the file if it doesn't exist yet)\n", "   2. `b` because we specifically want to write binary data. `pickle` uses a binary protocol, so it won't work if you don't include the `b`\n", "3. Then we can use the `dump` function from the `pickle` module to write our data object."]}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [], "source": ["with open('data.pickle', 'wb') as f:\n", "    pickle.dump(data_object, f)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Importing Objects from Pickle Files\n", "\n", "Go ahead and restart the kernel. Now if we try to access the original `data_object` it won't work:"]}, {"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["<class 'NameError'> name 'data_object' is not defined\n"]}], "source": ["try:\n", "    print(data_object)\n", "except NameError as e:\n", "    print(type(e), e)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["But we can use `pickle` to load it back into memory with a new name, `data_object2`.\n", "\n", "1. Open the file `data.pickle` since that is the file name we saved prior to restarting the kernel.\n", "2. We'll need to open the file using mode `'rb'`.\n", "   1. `r` for read\n", "   2. `b` for binary\n", "2. Then we can use the `load` function from the `pickle` module to read our data object."]}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [{"data": {"text/plain": ["{'a': [1, 2.0, 3, (4+6j)],\n", " 'b': ('character string', b'byte string'),\n", " 'c': {False, None, True}}"]}, "execution_count": 2, "metadata": {}, "output_type": "execute_result"}], "source": ["import pickle\n", "with open('data.pickle', 'rb') as f:\n", "    data_object2 = pickle.load(f)\n", "data_object2"]}, {"cell_type": "markdown", "metadata": {}, "source": ["***Important reminder:*** DO NOT open pickle files unless you trust the source (e.g. you created them yourself). They can contain malicious code and there are not any built-in security constraints on them."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Pickle with scikit-learn\n", "\n", "So far, your process has typically been to instantiate a model, train it, evaluate it, maybe make some predictions, then shut down the notebook. This means that the time and computational resources used to train the model are lost, and would need to be repeated if you ever wanted to use the model again.\n", "\n", "If you pickle your fitted model instead, then all you will need to do is load it back into memory, then it will be all ready to make predictions!"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Instantiating and Fitting a Model\n", "\n", "Below we fit a simple linear regression model:"]}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Fitted model is y = 1.0x + 1.0\n"]}], "source": ["from sklearn.linear_model import LinearRegression\n", "\n", "# y = x + 1\n", "X = [[1],[2],[3],[4],[5]]\n", "y = [2, 3, 4, 5, 6]\n", "\n", "model = LinearRegression()\n", "model.fit(X, y)\n", "\n", "print(f\"Fitted model is y = {model.coef_[0]}x + {model.intercept_}\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We can now use the model to make predictions:"]}, {"cell_type": "code", "execution_count": 4, "metadata": {}, "outputs": [{"data": {"text/plain": ["array([ 8.,  9., 10.])"]}, "execution_count": 4, "metadata": {}, "output_type": "execute_result"}], "source": ["model.predict([[7], [8], [9]])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Importing `joblib`\n", "\n", "For scikit-learn models, it is possible to use the `pickle` module but not recommended because it is less efficient. (See documentation [here](https://scikit-learn.org/stable/modules/model_persistence.html).) Instead, we'll use the `joblib` library.\n", "\n", "(Note that we still often use the language of \"pickle file\" and \"pickling\" even if we are using a different library such as `joblib`.)"]}, {"cell_type": "code", "execution_count": 5, "metadata": {}, "outputs": [], "source": ["import joblib"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Writing Objects with `joblib`\n", "\n", "Let's save `model` using `joblib`.\n", "\n", "1. Once again we need to open a file to store the model in.\n", "   1. Instead of `'data'`, we'll call this `'regression_model'` so it's clear what the file contains\n", "   2. Instead of the `.pickle` file extension, we'll use `.pkl`\n", "      1. This is the conventional file ending for scikit-learn models, and used to be the standard for all Python objects in Python 2\n", "      2. Neither Python nor `joblib` nor scikit-learn will enforce this file ending. So you also might see examples with `.pickle` or `.joblib` file extensions, or some other ending, even though it was serialized using this technique\n", "      3. If you see a serialized model ending with `.zip`, `.pb`, or `.h5`, that means it is likely not a scikit-learn model and probably was not serialized using `joblib` or `pickle`\n", "2. The mode (`'wb'`) is the same as with `pickle`.\n", "3. The function name (`dump`) is also the same as with `pickle`."]}, {"cell_type": "code", "execution_count": 6, "metadata": {}, "outputs": [], "source": ["with open('regression_model.pkl', 'wb') as f:\n", "    joblib.dump(model, f)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Importing Objects with `joblib`\n", "\n", "Now, restart the kernel. Once again, we would expect an error if we tried to use the `model` variable:"]}, {"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["<class 'NameError'> name 'model' is not defined\n"]}], "source": ["try:\n", "    print(model.predict([[10], [11], [12]]))\n", "except NameError as e:\n", "    print(type(e), e)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["But we can load the model from the pickled file:\n", "\n", "1. Open file `'regression_model.pkl'`.\n", "2. Use mode `'rb'`.\n", "3. Use the `load` function (this time from `joblib`)."]}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Loaded model is y = 1.0x + 1.0\n"]}], "source": ["import joblib\n", "with open('regression_model.pkl', 'rb') as f:\n", "    model2 = joblib.load(f)\n", "    \n", "print(f\"Loaded model is y = {model2.coef_[0]}x + {model2.intercept_}\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Note that the coefficient and intercept are the same as the original model. While this would have been a simple model to re-fit, you can imagine how this would save significant time with a more-complex model or with large production datasets.\n", "\n", "Now we can make predictions again!"]}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [{"data": {"text/plain": ["array([11., 12., 13.])"]}, "execution_count": 3, "metadata": {}, "output_type": "execute_result"}], "source": ["model2.predict([[10], [11], [12]])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Additional Resources\n", "\n", "* [Pickle Documentation](https://docs.python.org/3/library/pickle.html)\n", "* [scikit-learn Persistence Documentation (using `joblib`)](https://scikit-learn.org/stable/modules/model_persistence.html)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Summary \n", "\n", "In this brief lesson you saw how to both save objects to pickle files and import objects from pickle files. This can be particularly useful for saving models that are non deterministic and would otherwise be difficult or impossible to reproduce exact replicas of."]}], "metadata": {"kernelspec": {"display_name": "Python (learn-env)", "language": "python", "name": "learn-env"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.5"}}, "nbformat": 4, "nbformat_minor": 2}