{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Logistic Regression Model Comparisons - Lab\n", "\n", "## Introduction\n", "\n", "In this lab, you'll investigate using scikit-learn with regularization in order to produce better models.\n", "\n", "## Objectives\n", "\n", "- Compare the different inputs with logistic regression models and determine the optimal model "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Import the necessary packages"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Import the data\n", "\n", "Import the dataset stored in `'heart.csv'`."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Import the data\n", "\n", "df = None\n", "\n", "# Print the first five rows of the data\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Split the data\n", "\n", "Define `X` and `y` where the latter is the `target` variable. This time, follow best practices and also implement a standard train-test split. Assign 25% to the test set and set the `random_state` to 17. "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Define X and y\n", "y = None\n", "X = None\n", "\n", "# Split the data into training and test sets\n", "\n", "\n", "X_train, X_test, y_train, y_test = None\n", "print(y_train.value_counts(),'\\n\\n', y_test.value_counts())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Initial Model - scikit-learn\n", "\n", "Use scikit-learn to build the logistic regression model.\n", "\n", "Turn off the intercept and set the regularization parameter, `C`, to a ridiculously large number such as 1e16. "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Your code here"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Create an ROC Curve for the scikit-learn model\n", "\n", "Use both the training and test sets."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Your code here\n", "\n", "y_train_score = None\n", "y_test_score = None\n", "\n", "train_fpr, train_tpr, train_thresholds = None\n", "test_fpr, test_tpr, test_thresholds = None\n", "\n", "\n", "print('Train AUC: {}'.format(auc(train_fpr, train_tpr)))\n", "print('Test AUC: {}'.format(auc(test_fpr, test_tpr)))\n", "\n", "plt.figure(figsize=(10, 8))\n", "lw = 2\n", "\n", "plt.plot(train_fpr, train_tpr, color='blue',\n", "         lw=lw, label='Train ROC curve')\n", "plt.plot(test_fpr, test_tpr, color='darkorange',\n", "         lw=lw, label='Test ROC curve')\n", "\n", "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n", "plt.xlim([0.0, 1.0])\n", "plt.ylim([0.0, 1.05])\n", "plt.yticks([i/20.0 for i in range(21)])\n", "plt.xticks([i/20.0 for i in range(21)])\n", "plt.xlabel('False Positive Rate')\n", "plt.ylabel('True Positive Rate')\n", "plt.title('Receiver operating characteristic (ROC) Curve')\n", "plt.legend(loc='lower right')\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Add an Intercept\n", "\n", "Now add an intercept to the scikit-learn model. Keep the regularization parameter `C` set to a very large number such as 1e16. "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Create new model\n", "logregi = None\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Generate predictions for the training and test sets."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Generate predictions\n", "y_hat_train = None\n", "y_hat_test = None"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Plot all three models ROC curves on the same graph."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Initial model plots\n", "test_fpr, test_tpr, test_thresholds = roc_curve(y_test, y_hat_test)\n", "train_fpr, train_tpr, train_thresholds = roc_curve(y_train, y_hat_train)\n", "\n", "\n", "print('Custom Model Test AUC: {}'.format(auc(test_fpr, test_tpr)))\n", "print('Custome Model Train AUC: {}'.format(auc(train_fpr, train_tpr)))\n", "\n", "plt.figure(figsize=(10,8))\n", "lw = 2\n", "\n", "plt.plot(test_fpr, test_tpr, color='darkorange',\n", "         lw=lw, label='Custom Model Test ROC curve')\n", "plt.plot(train_fpr, train_tpr, color='blue',\n", "         lw=lw, label='Custom Model Train ROC curve')\n", "\n", "\n", "# Second model plots\n", "y_test_score = logreg.decision_function(X_test)\n", "y_train_score = logreg.decision_function(X_train)\n", "\n", "test_fpr, test_tpr, test_thresholds = roc_curve(y_test, y_test_score)\n", "train_fpr, train_tpr, train_thresholds = roc_curve(y_train, y_train_score)\n", "\n", "print('Scikit-learn Model 1 Test AUC: {}'.format(auc(test_fpr, test_tpr)))\n", "print('Scikit-learn Model 1 Train AUC: {}'.format(auc(train_fpr, train_tpr)))\n", "\n", "\n", "plt.plot(test_fpr, test_tpr, color='yellow',\n", "         lw=lw, label='Scikit learn Model 1 Test ROC curve')\n", "plt.plot(train_fpr, train_tpr, color='gold',\n", "         lw=lw, label='Scikit learn Model 1 Train ROC curve')\n", "\n", "\n", "# Third model plots\n", "y_test_score = None\n", "y_train_score = None\n", "\n", "test_fpr, test_tpr, test_thresholds = roc_curve(y_test, y_test_score)\n", "train_fpr, train_tpr, train_thresholds = roc_curve(y_train, y_train_score)\n", "\n", "print('Scikit-learn Model 2 with intercept Test AUC: {}'.format(auc(test_fpr, test_tpr)))\n", "print('Scikit-learn Model 2 with intercept Train AUC: {}'.format(auc(train_fpr, train_tpr)))\n", "\n", "\n", "plt.plot(test_fpr, test_tpr, color='purple',\n", "         lw=lw, label='Scikit learn Model 2 with intercept Test ROC curve')\n", "plt.plot(train_fpr, train_tpr, color='red',\n", "         lw=lw, label='Scikit learn Model 2 with intercept Train ROC curve')\n", "\n", "# Formatting\n", "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n", "plt.xlim([0.0, 1.0])\n", "plt.ylim([0.0, 1.05])\n", "plt.yticks([i/20.0 for i in range(21)])\n", "plt.xticks([i/20.0 for i in range(21)])\n", "plt.xlabel('False Positive Rate')\n", "plt.ylabel('True Positive Rate')\n", "plt.title('Receiver operating characteristic (ROC) Curve')\n", "plt.legend(loc=\"lower right\")\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Altering the Regularization Parameter\n", "\n", "Now, experiment with altering the regularization parameter. At a minimum, create 5 different subplots with varying regularization (`C`) parameters. For each, plot the ROC curve of the training and test set for that specific model.  \n", "\n", "Regularization parameters between 1 and 20 are recommended. Observe the difference in test and training AUC as you go along."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Your code here"]}, {"cell_type": "markdown", "metadata": {}, "source": ["How did the regularization parameter impact the ROC curves plotted above? "]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Summary\n", "\n", "In this lab, you reviewed many of the accuracy measures for classification algorithms and observed the impact of additional tuning models using intercepts and regularization."]}], "metadata": {"kernelspec": {"display_name": "Python (learn-env)", "language": "python", "name": "learn-env"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.16"}}, "nbformat": 4, "nbformat_minor": 2}