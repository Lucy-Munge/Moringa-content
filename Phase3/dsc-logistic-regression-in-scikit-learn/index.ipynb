{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Logistic Regression in scikit-learn\n", "\n", "\n", "## Introduction\n", "\n", "Generally, the process for fitting a logistic regression model using scikit-learn is very similar to that which you previously saw for `statsmodels`. One important exception is that scikit-learn will not display statistical measures such as the p-values associated with the various features. This is a shortcoming of scikit-learn, although scikit-learn has other useful tools for tuning models which we will investigate in future lessons.\n", "\n", "The other main process of model building and evaluation which we didn't discuss previously is performing a train-test split. As we saw in linear regression, model validation is an essential part of model building as it helps determine how our model will generalize to future unseen cases. After all, the point of any model is to provide future predictions where we don't already know the answer but have other informative data (`X`).\n", "\n", "With that, let's take a look at implementing logistic regression in scikit-learn using dummy variables and a proper train-test split.\n", "\n", "\n", "## Objectives\n", "\n", "You will be able to:\n", "\n", "- Fit a logistic regression model using scikit-learn "]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Importing the Data"]}, {"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [{"data": {"text/html": ["<div>\n", "<style scoped>\n", "    .dataframe tbody tr th:only-of-type {\n", "        vertical-align: middle;\n", "    }\n", "\n", "    .dataframe tbody tr th {\n", "        vertical-align: top;\n", "    }\n", "\n", "    .dataframe thead th {\n", "        text-align: right;\n", "    }\n", "</style>\n", "<table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", "    <tr style=\"text-align: right;\">\n", "      <th></th>\n", "      <th>PassengerId</th>\n", "      <th>Survived</th>\n", "      <th>Pclass</th>\n", "      <th>Name</th>\n", "      <th>Sex</th>\n", "      <th>Age</th>\n", "      <th>SibSp</th>\n", "      <th>Parch</th>\n", "      <th>Ticket</th>\n", "      <th>Fare</th>\n", "      <th>Cabin</th>\n", "      <th>Embarked</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <th>0</th>\n", "      <td>1</td>\n", "      <td>0</td>\n", "      <td>3</td>\n", "      <td>Braund, Mr. Owen Harris</td>\n", "      <td>male</td>\n", "      <td>22.0</td>\n", "      <td>1</td>\n", "      <td>0</td>\n", "      <td>A/5 21171</td>\n", "      <td>7.2500</td>\n", "      <td>NaN</td>\n", "      <td>S</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1</th>\n", "      <td>2</td>\n", "      <td>1</td>\n", "      <td>1</td>\n", "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n", "      <td>female</td>\n", "      <td>38.0</td>\n", "      <td>1</td>\n", "      <td>0</td>\n", "      <td>PC 17599</td>\n", "      <td>71.2833</td>\n", "      <td>C85</td>\n", "      <td>C</td>\n", "    </tr>\n", "    <tr>\n", "      <th>2</th>\n", "      <td>3</td>\n", "      <td>1</td>\n", "      <td>3</td>\n", "      <td>Heikkinen, Miss. Laina</td>\n", "      <td>female</td>\n", "      <td>26.0</td>\n", "      <td>0</td>\n", "      <td>0</td>\n", "      <td>STON/O2. 3101282</td>\n", "      <td>7.9250</td>\n", "      <td>NaN</td>\n", "      <td>S</td>\n", "    </tr>\n", "    <tr>\n", "      <th>3</th>\n", "      <td>4</td>\n", "      <td>1</td>\n", "      <td>1</td>\n", "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n", "      <td>female</td>\n", "      <td>35.0</td>\n", "      <td>1</td>\n", "      <td>0</td>\n", "      <td>113803</td>\n", "      <td>53.1000</td>\n", "      <td>C123</td>\n", "      <td>S</td>\n", "    </tr>\n", "    <tr>\n", "      <th>4</th>\n", "      <td>5</td>\n", "      <td>0</td>\n", "      <td>3</td>\n", "      <td>Allen, Mr. William Henry</td>\n", "      <td>male</td>\n", "      <td>35.0</td>\n", "      <td>0</td>\n", "      <td>0</td>\n", "      <td>373450</td>\n", "      <td>8.0500</td>\n", "      <td>NaN</td>\n", "      <td>S</td>\n", "    </tr>\n", "  </tbody>\n", "</table>\n", "</div>"], "text/plain": ["   PassengerId  Survived  Pclass  \\\n", "0            1         0       3   \n", "1            2         1       1   \n", "2            3         1       3   \n", "3            4         1       1   \n", "4            5         0       3   \n", "\n", "                                                Name     Sex   Age  SibSp  \\\n", "0                            Braund, Mr. Owen Harris    male  22.0      1   \n", "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n", "2                             Heikkinen, Miss. Laina  female  26.0      0   \n", "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n", "4                           Allen, Mr. William Henry    male  35.0      0   \n", "\n", "   Parch            Ticket     Fare Cabin Embarked  \n", "0      0         A/5 21171   7.2500   NaN        S  \n", "1      0          PC 17599  71.2833   C85        C  \n", "2      0  STON/O2. 3101282   7.9250   NaN        S  \n", "3      0            113803  53.1000  C123        S  \n", "4      0            373450   8.0500   NaN        S  "]}, "execution_count": 1, "metadata": {}, "output_type": "execute_result"}], "source": ["import pandas as pd\n", "\n", "df = pd.read_csv('titanic.csv')\n", "df.head()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Defining `X` and `y`\n", "\n", "To start out, we'll consider `y` to be the target variable (`Survived`) and everything else to be `X`."]}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [], "source": ["y = df[\"Survived\"]\n", "X = df.drop(\"Survived\", axis=1)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Train-Test Split\n", "\n", "Specifying a `random_state` means that we will get consistent results even if the kernel is restarted."]}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [], "source": ["from sklearn.model_selection import train_test_split\n", "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Preprocessing\n", "\n", "### Dealing with Missing Data\n", "\n", "Some of the data is missing, which won't work with a scikit-learn model:"]}, {"cell_type": "code", "execution_count": 4, "metadata": {}, "outputs": [{"data": {"text/plain": ["PassengerId      0\n", "Pclass           0\n", "Name             0\n", "Sex              0\n", "Age            133\n", "SibSp            0\n", "Parch            0\n", "Ticket           0\n", "Fare             0\n", "Cabin          511\n", "Embarked         2\n", "dtype: int64"]}, "execution_count": 4, "metadata": {}, "output_type": "execute_result"}], "source": ["X_train.isna().sum()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["For `Cabin` and `Embarked` (categorical features), we'll manually fill this in with \"missing\" labels:"]}, {"cell_type": "code", "execution_count": 5, "metadata": {}, "outputs": [{"data": {"text/plain": ["PassengerId      0\n", "Pclass           0\n", "Name             0\n", "Sex              0\n", "Age            133\n", "SibSp            0\n", "Parch            0\n", "Ticket           0\n", "Fare             0\n", "Cabin            0\n", "Embarked         0\n", "dtype: int64"]}, "execution_count": 5, "metadata": {}, "output_type": "execute_result"}], "source": ["X_train_fill_na = X_train.copy()\n", "X_train_fill_na.fillna({\"Cabin\":\"cabin_missing\", \"Embarked\":\"embarked_missing\"}, inplace=True)\n", "X_train_fill_na.isna().sum()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["For `Age` (a numeric feature), we'll use a `SimpleImputer` from scikit-learn ([documentation here](https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html)) to fill in the mean:"]}, {"cell_type": "code", "execution_count": 6, "metadata": {}, "outputs": [{"data": {"text/plain": ["PassengerId    0\n", "Pclass         0\n", "Name           0\n", "Sex            0\n", "Age            0\n", "SibSp          0\n", "Parch          0\n", "Ticket         0\n", "Fare           0\n", "Cabin          0\n", "Embarked       0\n", "dtype: int64"]}, "execution_count": 6, "metadata": {}, "output_type": "execute_result"}], "source": ["from sklearn.impute import SimpleImputer\n", "\n", "imputer = SimpleImputer()\n", "\n", "imputer.fit(X_train_fill_na[[\"Age\"]])\n", "age_imputed = pd.DataFrame(\n", "    imputer.transform(X_train_fill_na[[\"Age\"]]),\n", "    # index is important to ensure we can concatenate with other columns\n", "    index=X_train_fill_na.index,\n", "    columns=[\"Age\"]\n", ")\n", "\n", "X_train_fill_na[\"Age\"] = age_imputed\n", "X_train_fill_na.isna().sum()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Dealing with Categorical Data\n", "\n", "Some of the columns of `X_train_fill_na` currently contain categorical data (i.e. Dtype `object`):"]}, {"cell_type": "code", "execution_count": 7, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["<class 'pandas.core.frame.DataFrame'>\n", "Int64Index: 668 entries, 105 to 684\n", "Data columns (total 11 columns):\n", " #   Column       Non-Null Count  Dtype  \n", "---  ------       --------------  -----  \n", " 0   PassengerId  668 non-null    int64  \n", " 1   Pclass       668 non-null    int64  \n", " 2   Name         668 non-null    object \n", " 3   Sex          668 non-null    object \n", " 4   Age          668 non-null    float64\n", " 5   SibSp        668 non-null    int64  \n", " 6   Parch        668 non-null    int64  \n", " 7   Ticket       668 non-null    object \n", " 8   Fare         668 non-null    float64\n", " 9   Cabin        668 non-null    object \n", " 10  Embarked     668 non-null    object \n", "dtypes: float64(2), int64(4), object(5)\n", "memory usage: 62.6+ KB\n"]}], "source": ["X_train_fill_na.info()"]}, {"cell_type": "code", "execution_count": 8, "metadata": {}, "outputs": [{"data": {"text/html": ["<div>\n", "<style scoped>\n", "    .dataframe tbody tr th:only-of-type {\n", "        vertical-align: middle;\n", "    }\n", "\n", "    .dataframe tbody tr th {\n", "        vertical-align: top;\n", "    }\n", "\n", "    .dataframe thead th {\n", "        text-align: right;\n", "    }\n", "</style>\n", "<table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", "    <tr style=\"text-align: right;\">\n", "      <th></th>\n", "      <th>Name</th>\n", "      <th>Sex</th>\n", "      <th>Ticket</th>\n", "      <th>Cabin</th>\n", "      <th>Embarked</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <th>105</th>\n", "      <td>Mionoff, Mr. Stoytcho</td>\n", "      <td>male</td>\n", "      <td>349207</td>\n", "      <td>cabin_missing</td>\n", "      <td>S</td>\n", "    </tr>\n", "    <tr>\n", "      <th>68</th>\n", "      <td>Andersson, Miss. Erna Alexandra</td>\n", "      <td>female</td>\n", "      <td>3101281</td>\n", "      <td>cabin_missing</td>\n", "      <td>S</td>\n", "    </tr>\n", "    <tr>\n", "      <th>253</th>\n", "      <td>Lobb, Mr. William Arthur</td>\n", "      <td>male</td>\n", "      <td>A/5. 3336</td>\n", "      <td>cabin_missing</td>\n", "      <td>S</td>\n", "    </tr>\n", "    <tr>\n", "      <th>320</th>\n", "      <td>Dennis, Mr. Samuel</td>\n", "      <td>male</td>\n", "      <td>A/5 21172</td>\n", "      <td>cabin_missing</td>\n", "      <td>S</td>\n", "    </tr>\n", "    <tr>\n", "      <th>706</th>\n", "      <td>Kelly, Mrs. Florence \"Fannie\"</td>\n", "      <td>female</td>\n", "      <td>223596</td>\n", "      <td>cabin_missing</td>\n", "      <td>S</td>\n", "    </tr>\n", "    <tr>\n", "      <th>...</th>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "    </tr>\n", "    <tr>\n", "      <th>835</th>\n", "      <td>Compton, Miss. Sara Rebecca</td>\n", "      <td>female</td>\n", "      <td>PC 17756</td>\n", "      <td>E49</td>\n", "      <td>C</td>\n", "    </tr>\n", "    <tr>\n", "      <th>192</th>\n", "      <td>Andersen-Jensen, Miss. Carla Christine Nielsine</td>\n", "      <td>female</td>\n", "      <td>350046</td>\n", "      <td>cabin_missing</td>\n", "      <td>S</td>\n", "    </tr>\n", "    <tr>\n", "      <th>629</th>\n", "      <td>O'Connell, Mr. Patrick D</td>\n", "      <td>male</td>\n", "      <td>334912</td>\n", "      <td>cabin_missing</td>\n", "      <td>Q</td>\n", "    </tr>\n", "    <tr>\n", "      <th>559</th>\n", "      <td>de Messemaeker, Mrs. Guillaume Joseph (Emma)</td>\n", "      <td>female</td>\n", "      <td>345572</td>\n", "      <td>cabin_missing</td>\n", "      <td>S</td>\n", "    </tr>\n", "    <tr>\n", "      <th>684</th>\n", "      <td>Brown, Mr. Thomas William Solomon</td>\n", "      <td>male</td>\n", "      <td>29750</td>\n", "      <td>cabin_missing</td>\n", "      <td>S</td>\n", "    </tr>\n", "  </tbody>\n", "</table>\n", "<p>668 rows \u00d7 5 columns</p>\n", "</div>"], "text/plain": ["                                                Name     Sex     Ticket  \\\n", "105                            Mionoff, Mr. Stoytcho    male     349207   \n", "68                   Andersson, Miss. Erna Alexandra  female    3101281   \n", "253                         Lobb, Mr. William Arthur    male  A/5. 3336   \n", "320                               Dennis, Mr. Samuel    male  A/5 21172   \n", "706                    Kelly, Mrs. Florence \"Fannie\"  female     223596   \n", "..                                               ...     ...        ...   \n", "835                      Compton, Miss. Sara Rebecca  female   PC 17756   \n", "192  Andersen-Jensen, Miss. Carla Christine Nielsine  female     350046   \n", "629                         O'Connell, Mr. Patrick D    male     334912   \n", "559     de Messemaeker, Mrs. Guillaume Joseph (Emma)  female     345572   \n", "684                Brown, Mr. Thomas William Solomon    male      29750   \n", "\n", "             Cabin Embarked  \n", "105  cabin_missing        S  \n", "68   cabin_missing        S  \n", "253  cabin_missing        S  \n", "320  cabin_missing        S  \n", "706  cabin_missing        S  \n", "..             ...      ...  \n", "835            E49        C  \n", "192  cabin_missing        S  \n", "629  cabin_missing        Q  \n", "559  cabin_missing        S  \n", "684  cabin_missing        S  \n", "\n", "[668 rows x 5 columns]"]}, "execution_count": 8, "metadata": {}, "output_type": "execute_result"}], "source": ["X_train_categorical = X_train_fill_na.select_dtypes(exclude=[\"int64\", \"float64\"]).copy()\n", "X_train_categorical"]}, {"cell_type": "markdown", "metadata": {}, "source": ["`OneHotEncoder` from scikit-learn ([documentation here](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html)) can be used to convert categorical variables into dummy one-hot encoded variables:"]}, {"cell_type": "code", "execution_count": 9, "metadata": {}, "outputs": [{"data": {"text/html": ["<div>\n", "<style scoped>\n", "    .dataframe tbody tr th:only-of-type {\n", "        vertical-align: middle;\n", "    }\n", "\n", "    .dataframe tbody tr th {\n", "        vertical-align: top;\n", "    }\n", "\n", "    .dataframe thead th {\n", "        text-align: right;\n", "    }\n", "</style>\n", "<table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", "    <tr style=\"text-align: right;\">\n", "      <th></th>\n", "      <th>Abbing, Mr. Anthony</th>\n", "      <th>Abbott, Mr. Rossmore Edward</th>\n", "      <th>Abelson, Mrs. Samuel (Hannah Wizosky)</th>\n", "      <th>Adahl, Mr. Mauritz Nils Martin</th>\n", "      <th>Adams, Mr. John</th>\n", "      <th>Aks, Mrs. Sam (Leah Rosen)</th>\n", "      <th>Albimona, Mr. Nassef Cassem</th>\n", "      <th>Alexander, Mr. William</th>\n", "      <th>Alhomaki, Mr. Ilmari Rudolf</th>\n", "      <th>Allen, Miss. Elisabeth Walton</th>\n", "      <th>...</th>\n", "      <th>F33</th>\n", "      <th>F38</th>\n", "      <th>F4</th>\n", "      <th>G6</th>\n", "      <th>T</th>\n", "      <th>cabin_missing</th>\n", "      <th>C</th>\n", "      <th>Q</th>\n", "      <th>S</th>\n", "      <th>embarked_missing</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <th>105</th>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>...</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>68</th>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>...</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>253</th>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>...</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>320</th>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>...</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>706</th>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>...</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>...</th>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "    </tr>\n", "    <tr>\n", "      <th>835</th>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>...</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>192</th>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>...</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>629</th>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>...</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>559</th>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>...</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>684</th>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>...</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "    </tr>\n", "  </tbody>\n", "</table>\n", "<p>668 rows \u00d7 1336 columns</p>\n", "</div>"], "text/plain": ["     Abbing, Mr. Anthony  Abbott, Mr. Rossmore Edward  \\\n", "105                  0.0                          0.0   \n", "68                   0.0                          0.0   \n", "253                  0.0                          0.0   \n", "320                  0.0                          0.0   \n", "706                  0.0                          0.0   \n", "..                   ...                          ...   \n", "835                  0.0                          0.0   \n", "192                  0.0                          0.0   \n", "629                  0.0                          0.0   \n", "559                  0.0                          0.0   \n", "684                  0.0                          0.0   \n", "\n", "     Abelson, Mrs. Samuel (Hannah Wizosky)  Adahl, Mr. Mauritz Nils Martin  \\\n", "105                                    0.0                             0.0   \n", "68                                     0.0                             0.0   \n", "253                                    0.0                             0.0   \n", "320                                    0.0                             0.0   \n", "706                                    0.0                             0.0   \n", "..                                     ...                             ...   \n", "835                                    0.0                             0.0   \n", "192                                    0.0                             0.0   \n", "629                                    0.0                             0.0   \n", "559                                    0.0                             0.0   \n", "684                                    0.0                             0.0   \n", "\n", "     Adams, Mr. John  Aks, Mrs. Sam (Leah Rosen)  Albimona, Mr. Nassef Cassem  \\\n", "105              0.0                         0.0                          0.0   \n", "68               0.0                         0.0                          0.0   \n", "253              0.0                         0.0                          0.0   \n", "320              0.0                         0.0                          0.0   \n", "706              0.0                         0.0                          0.0   \n", "..               ...                         ...                          ...   \n", "835              0.0                         0.0                          0.0   \n", "192              0.0                         0.0                          0.0   \n", "629              0.0                         0.0                          0.0   \n", "559              0.0                         0.0                          0.0   \n", "684              0.0                         0.0                          0.0   \n", "\n", "     Alexander, Mr. William  Alhomaki, Mr. Ilmari Rudolf  \\\n", "105                     0.0                          0.0   \n", "68                      0.0                          0.0   \n", "253                     0.0                          0.0   \n", "320                     0.0                          0.0   \n", "706                     0.0                          0.0   \n", "..                      ...                          ...   \n", "835                     0.0                          0.0   \n", "192                     0.0                          0.0   \n", "629                     0.0                          0.0   \n", "559                     0.0                          0.0   \n", "684                     0.0                          0.0   \n", "\n", "     Allen, Miss. Elisabeth Walton  ...  F33  F38   F4   G6    T  \\\n", "105                            0.0  ...  0.0  0.0  0.0  0.0  0.0   \n", "68                             0.0  ...  0.0  0.0  0.0  0.0  0.0   \n", "253                            0.0  ...  0.0  0.0  0.0  0.0  0.0   \n", "320                            0.0  ...  0.0  0.0  0.0  0.0  0.0   \n", "706                            0.0  ...  0.0  0.0  0.0  0.0  0.0   \n", "..                             ...  ...  ...  ...  ...  ...  ...   \n", "835                            0.0  ...  0.0  0.0  0.0  0.0  0.0   \n", "192                            0.0  ...  0.0  0.0  0.0  0.0  0.0   \n", "629                            0.0  ...  0.0  0.0  0.0  0.0  0.0   \n", "559                            0.0  ...  0.0  0.0  0.0  0.0  0.0   \n", "684                            0.0  ...  0.0  0.0  0.0  0.0  0.0   \n", "\n", "     cabin_missing    C    Q    S  embarked_missing  \n", "105            1.0  0.0  0.0  1.0               0.0  \n", "68             1.0  0.0  0.0  1.0               0.0  \n", "253            1.0  0.0  0.0  1.0               0.0  \n", "320            1.0  0.0  0.0  1.0               0.0  \n", "706            1.0  0.0  0.0  1.0               0.0  \n", "..             ...  ...  ...  ...               ...  \n", "835            0.0  1.0  0.0  0.0               0.0  \n", "192            1.0  0.0  0.0  1.0               0.0  \n", "629            1.0  0.0  1.0  0.0               0.0  \n", "559            1.0  0.0  0.0  1.0               0.0  \n", "684            1.0  0.0  0.0  1.0               0.0  \n", "\n", "[668 rows x 1336 columns]"]}, "execution_count": 9, "metadata": {}, "output_type": "execute_result"}], "source": ["from sklearn.preprocessing import OneHotEncoder\n", "import numpy as np\n", "\n", "ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n", "\n", "ohe.fit(X_train_categorical)\n", "X_train_ohe = pd.DataFrame(\n", "    ohe.transform(X_train_categorical),\n", "    # index is important to ensure we can concatenate with other columns\n", "    index=X_train_categorical.index,\n", "    # we are dummying multiple columns at once, so stack the names\n", "    columns=np.hstack(ohe.categories_)\n", ")\n", "X_train_ohe"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Wow! That's a lot of columns! Way more than is useful in practice: we now have columns for each of the passenger's names. This is an example of what not to do. Let's try that again, this time being mindful of which variables we actually want to include in our model.\n", "\n", "Instead of just selecting every single categorical feature for dummying, let's only include the ones that make sense as categories rather than being the names of individual people:"]}, {"cell_type": "code", "execution_count": 10, "metadata": {}, "outputs": [{"data": {"text/html": ["<div>\n", "<style scoped>\n", "    .dataframe tbody tr th:only-of-type {\n", "        vertical-align: middle;\n", "    }\n", "\n", "    .dataframe tbody tr th {\n", "        vertical-align: top;\n", "    }\n", "\n", "    .dataframe thead th {\n", "        text-align: right;\n", "    }\n", "</style>\n", "<table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", "    <tr style=\"text-align: right;\">\n", "      <th></th>\n", "      <th>Sex</th>\n", "      <th>Cabin</th>\n", "      <th>Embarked</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <th>105</th>\n", "      <td>male</td>\n", "      <td>cabin_missing</td>\n", "      <td>S</td>\n", "    </tr>\n", "    <tr>\n", "      <th>68</th>\n", "      <td>female</td>\n", "      <td>cabin_missing</td>\n", "      <td>S</td>\n", "    </tr>\n", "    <tr>\n", "      <th>253</th>\n", "      <td>male</td>\n", "      <td>cabin_missing</td>\n", "      <td>S</td>\n", "    </tr>\n", "    <tr>\n", "      <th>320</th>\n", "      <td>male</td>\n", "      <td>cabin_missing</td>\n", "      <td>S</td>\n", "    </tr>\n", "    <tr>\n", "      <th>706</th>\n", "      <td>female</td>\n", "      <td>cabin_missing</td>\n", "      <td>S</td>\n", "    </tr>\n", "    <tr>\n", "      <th>...</th>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "    </tr>\n", "    <tr>\n", "      <th>835</th>\n", "      <td>female</td>\n", "      <td>E49</td>\n", "      <td>C</td>\n", "    </tr>\n", "    <tr>\n", "      <th>192</th>\n", "      <td>female</td>\n", "      <td>cabin_missing</td>\n", "      <td>S</td>\n", "    </tr>\n", "    <tr>\n", "      <th>629</th>\n", "      <td>male</td>\n", "      <td>cabin_missing</td>\n", "      <td>Q</td>\n", "    </tr>\n", "    <tr>\n", "      <th>559</th>\n", "      <td>female</td>\n", "      <td>cabin_missing</td>\n", "      <td>S</td>\n", "    </tr>\n", "    <tr>\n", "      <th>684</th>\n", "      <td>male</td>\n", "      <td>cabin_missing</td>\n", "      <td>S</td>\n", "    </tr>\n", "  </tbody>\n", "</table>\n", "<p>668 rows \u00d7 3 columns</p>\n", "</div>"], "text/plain": ["        Sex          Cabin Embarked\n", "105    male  cabin_missing        S\n", "68   female  cabin_missing        S\n", "253    male  cabin_missing        S\n", "320    male  cabin_missing        S\n", "706  female  cabin_missing        S\n", "..      ...            ...      ...\n", "835  female            E49        C\n", "192  female  cabin_missing        S\n", "629    male  cabin_missing        Q\n", "559  female  cabin_missing        S\n", "684    male  cabin_missing        S\n", "\n", "[668 rows x 3 columns]"]}, "execution_count": 10, "metadata": {}, "output_type": "execute_result"}], "source": ["categorical_features = [\"Sex\", \"Cabin\", \"Embarked\"]\n", "X_train_categorical = X_train_fill_na[categorical_features].copy()\n", "X_train_categorical"]}, {"cell_type": "code", "execution_count": 11, "metadata": {}, "outputs": [{"data": {"text/html": ["<div>\n", "<style scoped>\n", "    .dataframe tbody tr th:only-of-type {\n", "        vertical-align: middle;\n", "    }\n", "\n", "    .dataframe tbody tr th {\n", "        vertical-align: top;\n", "    }\n", "\n", "    .dataframe thead th {\n", "        text-align: right;\n", "    }\n", "</style>\n", "<table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", "    <tr style=\"text-align: right;\">\n", "      <th></th>\n", "      <th>female</th>\n", "      <th>male</th>\n", "      <th>A10</th>\n", "      <th>A14</th>\n", "      <th>A16</th>\n", "      <th>A19</th>\n", "      <th>A20</th>\n", "      <th>A23</th>\n", "      <th>A24</th>\n", "      <th>A31</th>\n", "      <th>...</th>\n", "      <th>F33</th>\n", "      <th>F38</th>\n", "      <th>F4</th>\n", "      <th>G6</th>\n", "      <th>T</th>\n", "      <th>cabin_missing</th>\n", "      <th>C</th>\n", "      <th>Q</th>\n", "      <th>S</th>\n", "      <th>embarked_missing</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <th>105</th>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>...</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>68</th>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>...</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>253</th>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>...</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>320</th>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>...</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>706</th>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>...</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>...</th>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "    </tr>\n", "    <tr>\n", "      <th>835</th>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>...</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>192</th>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>...</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>629</th>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>...</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>559</th>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>...</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>684</th>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>...</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "    </tr>\n", "  </tbody>\n", "</table>\n", "<p>668 rows \u00d7 130 columns</p>\n", "</div>"], "text/plain": ["     female  male  A10  A14  A16  A19  A20  A23  A24  A31  ...  F33  F38   F4  \\\n", "105     0.0   1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n", "68      1.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n", "253     0.0   1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n", "320     0.0   1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n", "706     1.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n", "..      ...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n", "835     1.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n", "192     1.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n", "629     0.0   1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n", "559     1.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n", "684     0.0   1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n", "\n", "      G6    T  cabin_missing    C    Q    S  embarked_missing  \n", "105  0.0  0.0            1.0  0.0  0.0  1.0               0.0  \n", "68   0.0  0.0            1.0  0.0  0.0  1.0               0.0  \n", "253  0.0  0.0            1.0  0.0  0.0  1.0               0.0  \n", "320  0.0  0.0            1.0  0.0  0.0  1.0               0.0  \n", "706  0.0  0.0            1.0  0.0  0.0  1.0               0.0  \n", "..   ...  ...            ...  ...  ...  ...               ...  \n", "835  0.0  0.0            0.0  1.0  0.0  0.0               0.0  \n", "192  0.0  0.0            1.0  0.0  0.0  1.0               0.0  \n", "629  0.0  0.0            1.0  0.0  1.0  0.0               0.0  \n", "559  0.0  0.0            1.0  0.0  0.0  1.0               0.0  \n", "684  0.0  0.0            1.0  0.0  0.0  1.0               0.0  \n", "\n", "[668 rows x 130 columns]"]}, "execution_count": 11, "metadata": {}, "output_type": "execute_result"}], "source": ["ohe.fit(X_train_categorical)\n", "\n", "X_train_ohe = pd.DataFrame(\n", "    ohe.transform(X_train_categorical),\n", "    index=X_train_categorical.index,\n", "    columns=np.hstack(ohe.categories_)\n", ")\n", "X_train_ohe"]}, {"cell_type": "markdown", "metadata": {}, "source": ["That's still a lot of columns, but we no longer have more columns than records!"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Normalization\n", "\n", "Now let's look at the numeric features. This time we'll also pay more attention to the meaning of the features, and only include relevant ones (e.g. not including `PassengerId` because this is a data artifact, not a true feature).\n", "\n", "Another important data preparation practice is to normalize your data. That is, if the features are on different scales, some features may impact the model more heavily then others. To level the playing field, we often normalize all features to a consistent scale of 0 to 1.\n", "\n", "As you can see, our features are currently not on a consistent scale:"]}, {"cell_type": "code", "execution_count": 12, "metadata": {}, "outputs": [{"data": {"text/html": ["<div>\n", "<style scoped>\n", "    .dataframe tbody tr th:only-of-type {\n", "        vertical-align: middle;\n", "    }\n", "\n", "    .dataframe tbody tr th {\n", "        vertical-align: top;\n", "    }\n", "\n", "    .dataframe thead th {\n", "        text-align: right;\n", "    }\n", "</style>\n", "<table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", "    <tr style=\"text-align: right;\">\n", "      <th></th>\n", "      <th>Pclass</th>\n", "      <th>Age</th>\n", "      <th>SibSp</th>\n", "      <th>Fare</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <th>105</th>\n", "      <td>3</td>\n", "      <td>28.0</td>\n", "      <td>0</td>\n", "      <td>7.8958</td>\n", "    </tr>\n", "    <tr>\n", "      <th>68</th>\n", "      <td>3</td>\n", "      <td>17.0</td>\n", "      <td>4</td>\n", "      <td>7.9250</td>\n", "    </tr>\n", "    <tr>\n", "      <th>253</th>\n", "      <td>3</td>\n", "      <td>30.0</td>\n", "      <td>1</td>\n", "      <td>16.1000</td>\n", "    </tr>\n", "    <tr>\n", "      <th>320</th>\n", "      <td>3</td>\n", "      <td>22.0</td>\n", "      <td>0</td>\n", "      <td>7.2500</td>\n", "    </tr>\n", "    <tr>\n", "      <th>706</th>\n", "      <td>2</td>\n", "      <td>45.0</td>\n", "      <td>0</td>\n", "      <td>13.5000</td>\n", "    </tr>\n", "    <tr>\n", "      <th>...</th>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "    </tr>\n", "    <tr>\n", "      <th>835</th>\n", "      <td>1</td>\n", "      <td>39.0</td>\n", "      <td>1</td>\n", "      <td>83.1583</td>\n", "    </tr>\n", "    <tr>\n", "      <th>192</th>\n", "      <td>3</td>\n", "      <td>19.0</td>\n", "      <td>1</td>\n", "      <td>7.8542</td>\n", "    </tr>\n", "    <tr>\n", "      <th>629</th>\n", "      <td>3</td>\n", "      <td>29.9</td>\n", "      <td>0</td>\n", "      <td>7.7333</td>\n", "    </tr>\n", "    <tr>\n", "      <th>559</th>\n", "      <td>3</td>\n", "      <td>36.0</td>\n", "      <td>1</td>\n", "      <td>17.4000</td>\n", "    </tr>\n", "    <tr>\n", "      <th>684</th>\n", "      <td>2</td>\n", "      <td>60.0</td>\n", "      <td>1</td>\n", "      <td>39.0000</td>\n", "    </tr>\n", "  </tbody>\n", "</table>\n", "<p>668 rows \u00d7 4 columns</p>\n", "</div>"], "text/plain": ["     Pclass   Age  SibSp     Fare\n", "105       3  28.0      0   7.8958\n", "68        3  17.0      4   7.9250\n", "253       3  30.0      1  16.1000\n", "320       3  22.0      0   7.2500\n", "706       2  45.0      0  13.5000\n", "..      ...   ...    ...      ...\n", "835       1  39.0      1  83.1583\n", "192       3  19.0      1   7.8542\n", "629       3  29.9      0   7.7333\n", "559       3  36.0      1  17.4000\n", "684       2  60.0      1  39.0000\n", "\n", "[668 rows x 4 columns]"]}, "execution_count": 12, "metadata": {}, "output_type": "execute_result"}], "source": ["numeric_features = [\"Pclass\", \"Age\", \"SibSp\", \"Fare\"]\n", "X_train_numeric = X_train_fill_na[numeric_features].copy()\n", "X_train_numeric"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Let's use a `MinMaxScaler` from scikit-learn ([documentation here](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html)) with default parameters to create a maximum value of 1 and a minimum value of 0. This will work well with our binary one-hot encoded data."]}, {"cell_type": "code", "execution_count": 13, "metadata": {}, "outputs": [{"data": {"text/html": ["<div>\n", "<style scoped>\n", "    .dataframe tbody tr th:only-of-type {\n", "        vertical-align: middle;\n", "    }\n", "\n", "    .dataframe tbody tr th {\n", "        vertical-align: top;\n", "    }\n", "\n", "    .dataframe thead th {\n", "        text-align: right;\n", "    }\n", "</style>\n", "<table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", "    <tr style=\"text-align: right;\">\n", "      <th></th>\n", "      <th>Pclass</th>\n", "      <th>Age</th>\n", "      <th>SibSp</th>\n", "      <th>Fare</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <th>105</th>\n", "      <td>1.0</td>\n", "      <td>0.344510</td>\n", "      <td>0.000</td>\n", "      <td>0.015412</td>\n", "    </tr>\n", "    <tr>\n", "      <th>68</th>\n", "      <td>1.0</td>\n", "      <td>0.205849</td>\n", "      <td>0.500</td>\n", "      <td>0.015469</td>\n", "    </tr>\n", "    <tr>\n", "      <th>253</th>\n", "      <td>1.0</td>\n", "      <td>0.369721</td>\n", "      <td>0.125</td>\n", "      <td>0.031425</td>\n", "    </tr>\n", "    <tr>\n", "      <th>320</th>\n", "      <td>1.0</td>\n", "      <td>0.268877</td>\n", "      <td>0.000</td>\n", "      <td>0.014151</td>\n", "    </tr>\n", "    <tr>\n", "      <th>706</th>\n", "      <td>0.5</td>\n", "      <td>0.558805</td>\n", "      <td>0.000</td>\n", "      <td>0.026350</td>\n", "    </tr>\n", "    <tr>\n", "      <th>...</th>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "    </tr>\n", "    <tr>\n", "      <th>835</th>\n", "      <td>0.0</td>\n", "      <td>0.483172</td>\n", "      <td>0.125</td>\n", "      <td>0.162314</td>\n", "    </tr>\n", "    <tr>\n", "      <th>192</th>\n", "      <td>1.0</td>\n", "      <td>0.231060</td>\n", "      <td>0.125</td>\n", "      <td>0.015330</td>\n", "    </tr>\n", "    <tr>\n", "      <th>629</th>\n", "      <td>1.0</td>\n", "      <td>0.368461</td>\n", "      <td>0.000</td>\n", "      <td>0.015094</td>\n", "    </tr>\n", "    <tr>\n", "      <th>559</th>\n", "      <td>1.0</td>\n", "      <td>0.445355</td>\n", "      <td>0.125</td>\n", "      <td>0.033963</td>\n", "    </tr>\n", "    <tr>\n", "      <th>684</th>\n", "      <td>0.5</td>\n", "      <td>0.747889</td>\n", "      <td>0.125</td>\n", "      <td>0.076123</td>\n", "    </tr>\n", "  </tbody>\n", "</table>\n", "<p>668 rows \u00d7 4 columns</p>\n", "</div>"], "text/plain": ["     Pclass       Age  SibSp      Fare\n", "105     1.0  0.344510  0.000  0.015412\n", "68      1.0  0.205849  0.500  0.015469\n", "253     1.0  0.369721  0.125  0.031425\n", "320     1.0  0.268877  0.000  0.014151\n", "706     0.5  0.558805  0.000  0.026350\n", "..      ...       ...    ...       ...\n", "835     0.0  0.483172  0.125  0.162314\n", "192     1.0  0.231060  0.125  0.015330\n", "629     1.0  0.368461  0.000  0.015094\n", "559     1.0  0.445355  0.125  0.033963\n", "684     0.5  0.747889  0.125  0.076123\n", "\n", "[668 rows x 4 columns]"]}, "execution_count": 13, "metadata": {}, "output_type": "execute_result"}], "source": ["from sklearn.preprocessing import MinMaxScaler\n", "\n", "scaler = MinMaxScaler()\n", "\n", "scaler.fit(X_train_numeric)\n", "X_train_scaled = pd.DataFrame(\n", "    scaler.transform(X_train_numeric),\n", "    # index is important to ensure we can concatenate with other columns\n", "    index=X_train_numeric.index,\n", "    columns=X_train_numeric.columns\n", ")\n", "X_train_scaled"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Then we concatenate everything together:"]}, {"cell_type": "code", "execution_count": 14, "metadata": {}, "outputs": [{"data": {"text/html": ["<div>\n", "<style scoped>\n", "    .dataframe tbody tr th:only-of-type {\n", "        vertical-align: middle;\n", "    }\n", "\n", "    .dataframe tbody tr th {\n", "        vertical-align: top;\n", "    }\n", "\n", "    .dataframe thead th {\n", "        text-align: right;\n", "    }\n", "</style>\n", "<table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", "    <tr style=\"text-align: right;\">\n", "      <th></th>\n", "      <th>Pclass</th>\n", "      <th>Age</th>\n", "      <th>SibSp</th>\n", "      <th>Fare</th>\n", "      <th>female</th>\n", "      <th>male</th>\n", "      <th>A10</th>\n", "      <th>A14</th>\n", "      <th>A16</th>\n", "      <th>A19</th>\n", "      <th>...</th>\n", "      <th>F33</th>\n", "      <th>F38</th>\n", "      <th>F4</th>\n", "      <th>G6</th>\n", "      <th>T</th>\n", "      <th>cabin_missing</th>\n", "      <th>C</th>\n", "      <th>Q</th>\n", "      <th>S</th>\n", "      <th>embarked_missing</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <th>105</th>\n", "      <td>1.0</td>\n", "      <td>0.344510</td>\n", "      <td>0.000</td>\n", "      <td>0.015412</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>...</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>68</th>\n", "      <td>1.0</td>\n", "      <td>0.205849</td>\n", "      <td>0.500</td>\n", "      <td>0.015469</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>...</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>253</th>\n", "      <td>1.0</td>\n", "      <td>0.369721</td>\n", "      <td>0.125</td>\n", "      <td>0.031425</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>...</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>320</th>\n", "      <td>1.0</td>\n", "      <td>0.268877</td>\n", "      <td>0.000</td>\n", "      <td>0.014151</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>...</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>706</th>\n", "      <td>0.5</td>\n", "      <td>0.558805</td>\n", "      <td>0.000</td>\n", "      <td>0.026350</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>...</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>...</th>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "    </tr>\n", "    <tr>\n", "      <th>835</th>\n", "      <td>0.0</td>\n", "      <td>0.483172</td>\n", "      <td>0.125</td>\n", "      <td>0.162314</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>...</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>192</th>\n", "      <td>1.0</td>\n", "      <td>0.231060</td>\n", "      <td>0.125</td>\n", "      <td>0.015330</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>...</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>629</th>\n", "      <td>1.0</td>\n", "      <td>0.368461</td>\n", "      <td>0.000</td>\n", "      <td>0.015094</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>...</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>559</th>\n", "      <td>1.0</td>\n", "      <td>0.445355</td>\n", "      <td>0.125</td>\n", "      <td>0.033963</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>...</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>684</th>\n", "      <td>0.5</td>\n", "      <td>0.747889</td>\n", "      <td>0.125</td>\n", "      <td>0.076123</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>...</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "    </tr>\n", "  </tbody>\n", "</table>\n", "<p>668 rows \u00d7 134 columns</p>\n", "</div>"], "text/plain": ["     Pclass       Age  SibSp      Fare  female  male  A10  A14  A16  A19  ...  \\\n", "105     1.0  0.344510  0.000  0.015412     0.0   1.0  0.0  0.0  0.0  0.0  ...   \n", "68      1.0  0.205849  0.500  0.015469     1.0   0.0  0.0  0.0  0.0  0.0  ...   \n", "253     1.0  0.369721  0.125  0.031425     0.0   1.0  0.0  0.0  0.0  0.0  ...   \n", "320     1.0  0.268877  0.000  0.014151     0.0   1.0  0.0  0.0  0.0  0.0  ...   \n", "706     0.5  0.558805  0.000  0.026350     1.0   0.0  0.0  0.0  0.0  0.0  ...   \n", "..      ...       ...    ...       ...     ...   ...  ...  ...  ...  ...  ...   \n", "835     0.0  0.483172  0.125  0.162314     1.0   0.0  0.0  0.0  0.0  0.0  ...   \n", "192     1.0  0.231060  0.125  0.015330     1.0   0.0  0.0  0.0  0.0  0.0  ...   \n", "629     1.0  0.368461  0.000  0.015094     0.0   1.0  0.0  0.0  0.0  0.0  ...   \n", "559     1.0  0.445355  0.125  0.033963     1.0   0.0  0.0  0.0  0.0  0.0  ...   \n", "684     0.5  0.747889  0.125  0.076123     0.0   1.0  0.0  0.0  0.0  0.0  ...   \n", "\n", "     F33  F38   F4   G6    T  cabin_missing    C    Q    S  embarked_missing  \n", "105  0.0  0.0  0.0  0.0  0.0            1.0  0.0  0.0  1.0               0.0  \n", "68   0.0  0.0  0.0  0.0  0.0            1.0  0.0  0.0  1.0               0.0  \n", "253  0.0  0.0  0.0  0.0  0.0            1.0  0.0  0.0  1.0               0.0  \n", "320  0.0  0.0  0.0  0.0  0.0            1.0  0.0  0.0  1.0               0.0  \n", "706  0.0  0.0  0.0  0.0  0.0            1.0  0.0  0.0  1.0               0.0  \n", "..   ...  ...  ...  ...  ...            ...  ...  ...  ...               ...  \n", "835  0.0  0.0  0.0  0.0  0.0            0.0  1.0  0.0  0.0               0.0  \n", "192  0.0  0.0  0.0  0.0  0.0            1.0  0.0  0.0  1.0               0.0  \n", "629  0.0  0.0  0.0  0.0  0.0            1.0  0.0  1.0  0.0               0.0  \n", "559  0.0  0.0  0.0  0.0  0.0            1.0  0.0  0.0  1.0               0.0  \n", "684  0.0  0.0  0.0  0.0  0.0            1.0  0.0  0.0  1.0               0.0  \n", "\n", "[668 rows x 134 columns]"]}, "execution_count": 14, "metadata": {}, "output_type": "execute_result"}], "source": ["X_train_full = pd.concat([X_train_scaled, X_train_ohe], axis=1)\n", "X_train_full"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Fitting a Model\n", "\n", "Now let's fit a model to the preprocessed training set. In scikit-learn, you do this by first creating an instance of the `LogisticRegression` class. From there, then use the `.fit()` method from your class instance to fit a model to the training data."]}, {"cell_type": "code", "execution_count": 15, "metadata": {}, "outputs": [{"data": {"text/plain": ["LogisticRegression(C=1000000000000.0, fit_intercept=False, solver='liblinear')"]}, "execution_count": 15, "metadata": {}, "output_type": "execute_result"}], "source": ["from sklearn.linear_model import LogisticRegression\n", "\n", "logreg = LogisticRegression(fit_intercept=False, C=1e12, solver='liblinear')\n", "model_log = logreg.fit(X_train_full, y_train)\n", "model_log"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Model Evaluation\n", "\n", "Now that we have a model, lets take a look at how it performs.\n", "\n", "### Performance on Training Data\n", "\n", "First, how does it perform on the training data?\n", "\n", "In the cell below, `0` means the prediction and the actual value matched, whereas `1` means the prediction and the actual value did not match."]}, {"cell_type": "code", "execution_count": 16, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["0    567\n", "1    101\n", "Name: Residuals (counts), dtype: int64\n", "\n", "0    0.848802\n", "1    0.151198\n", "Name: Residuals (proportions), dtype: float64\n"]}], "source": ["y_hat_train = logreg.predict(X_train_full)\n", "\n", "train_residuals = np.abs(y_train - y_hat_train)\n", "print(pd.Series(train_residuals, name=\"Residuals (counts)\").value_counts())\n", "print()\n", "print(pd.Series(train_residuals, name=\"Residuals (proportions)\").value_counts(normalize=True))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Not bad; our classifier was about 85% correct on our training data!"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Performance on Test Data\n", "\n", "Now let's apply the same preprocessing process to our test data, so we can evaluate the model's performance on unseen data."]}, {"cell_type": "code", "execution_count": 17, "metadata": {}, "outputs": [{"data": {"text/html": ["<div>\n", "<style scoped>\n", "    .dataframe tbody tr th:only-of-type {\n", "        vertical-align: middle;\n", "    }\n", "\n", "    .dataframe tbody tr th {\n", "        vertical-align: top;\n", "    }\n", "\n", "    .dataframe thead th {\n", "        text-align: right;\n", "    }\n", "</style>\n", "<table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", "    <tr style=\"text-align: right;\">\n", "      <th></th>\n", "      <th>Pclass</th>\n", "      <th>Age</th>\n", "      <th>SibSp</th>\n", "      <th>Fare</th>\n", "      <th>female</th>\n", "      <th>male</th>\n", "      <th>A10</th>\n", "      <th>A14</th>\n", "      <th>A16</th>\n", "      <th>A19</th>\n", "      <th>...</th>\n", "      <th>F33</th>\n", "      <th>F38</th>\n", "      <th>F4</th>\n", "      <th>G6</th>\n", "      <th>T</th>\n", "      <th>cabin_missing</th>\n", "      <th>C</th>\n", "      <th>Q</th>\n", "      <th>S</th>\n", "      <th>embarked_missing</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <th>495</th>\n", "      <td>1.0</td>\n", "      <td>0.368461</td>\n", "      <td>0.000</td>\n", "      <td>0.028221</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>...</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>648</th>\n", "      <td>1.0</td>\n", "      <td>0.368461</td>\n", "      <td>0.000</td>\n", "      <td>0.014737</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>...</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>278</th>\n", "      <td>1.0</td>\n", "      <td>0.079793</td>\n", "      <td>0.500</td>\n", "      <td>0.056848</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>...</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>31</th>\n", "      <td>0.0</td>\n", "      <td>0.368461</td>\n", "      <td>0.125</td>\n", "      <td>0.285990</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>...</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>255</th>\n", "      <td>1.0</td>\n", "      <td>0.357116</td>\n", "      <td>0.000</td>\n", "      <td>0.029758</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>...</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>...</th>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "      <td>...</td>\n", "    </tr>\n", "    <tr>\n", "      <th>167</th>\n", "      <td>1.0</td>\n", "      <td>0.558805</td>\n", "      <td>0.125</td>\n", "      <td>0.054457</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>...</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>306</th>\n", "      <td>0.0</td>\n", "      <td>0.368461</td>\n", "      <td>0.000</td>\n", "      <td>0.216430</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>...</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>379</th>\n", "      <td>1.0</td>\n", "      <td>0.231060</td>\n", "      <td>0.000</td>\n", "      <td>0.015176</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>...</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>742</th>\n", "      <td>0.0</td>\n", "      <td>0.256271</td>\n", "      <td>0.250</td>\n", "      <td>0.512122</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>...</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "    </tr>\n", "    <tr>\n", "      <th>10</th>\n", "      <td>1.0</td>\n", "      <td>0.041977</td>\n", "      <td>0.125</td>\n", "      <td>0.032596</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>...</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>0.0</td>\n", "      <td>1.0</td>\n", "      <td>0.0</td>\n", "    </tr>\n", "  </tbody>\n", "</table>\n", "<p>223 rows \u00d7 134 columns</p>\n", "</div>"], "text/plain": ["     Pclass       Age  SibSp      Fare  female  male  A10  A14  A16  A19  ...  \\\n", "495     1.0  0.368461  0.000  0.028221     0.0   1.0  0.0  0.0  0.0  0.0  ...   \n", "648     1.0  0.368461  0.000  0.014737     0.0   1.0  0.0  0.0  0.0  0.0  ...   \n", "278     1.0  0.079793  0.500  0.056848     0.0   1.0  0.0  0.0  0.0  0.0  ...   \n", "31      0.0  0.368461  0.125  0.285990     1.0   0.0  0.0  0.0  0.0  0.0  ...   \n", "255     1.0  0.357116  0.000  0.029758     1.0   0.0  0.0  0.0  0.0  0.0  ...   \n", "..      ...       ...    ...       ...     ...   ...  ...  ...  ...  ...  ...   \n", "167     1.0  0.558805  0.125  0.054457     1.0   0.0  0.0  0.0  0.0  0.0  ...   \n", "306     0.0  0.368461  0.000  0.216430     1.0   0.0  0.0  0.0  0.0  0.0  ...   \n", "379     1.0  0.231060  0.000  0.015176     0.0   1.0  0.0  0.0  0.0  0.0  ...   \n", "742     0.0  0.256271  0.250  0.512122     1.0   0.0  0.0  0.0  0.0  0.0  ...   \n", "10      1.0  0.041977  0.125  0.032596     1.0   0.0  0.0  0.0  0.0  0.0  ...   \n", "\n", "     F33  F38   F4   G6    T  cabin_missing    C    Q    S  embarked_missing  \n", "495  0.0  0.0  0.0  0.0  0.0            1.0  1.0  0.0  0.0               0.0  \n", "648  0.0  0.0  0.0  0.0  0.0            1.0  0.0  0.0  1.0               0.0  \n", "278  0.0  0.0  0.0  0.0  0.0            1.0  0.0  1.0  0.0               0.0  \n", "31   0.0  0.0  0.0  0.0  0.0            0.0  1.0  0.0  0.0               0.0  \n", "255  0.0  0.0  0.0  0.0  0.0            1.0  1.0  0.0  0.0               0.0  \n", "..   ...  ...  ...  ...  ...            ...  ...  ...  ...               ...  \n", "167  0.0  0.0  0.0  0.0  0.0            1.0  0.0  0.0  1.0               0.0  \n", "306  0.0  0.0  0.0  0.0  0.0            1.0  1.0  0.0  0.0               0.0  \n", "379  0.0  0.0  0.0  0.0  0.0            1.0  0.0  0.0  1.0               0.0  \n", "742  0.0  0.0  0.0  0.0  0.0            0.0  1.0  0.0  0.0               0.0  \n", "10   0.0  0.0  0.0  1.0  0.0            0.0  0.0  0.0  1.0               0.0  \n", "\n", "[223 rows x 134 columns]"]}, "execution_count": 17, "metadata": {}, "output_type": "execute_result"}], "source": ["# Filling in missing categorical data\n", "X_test_fill_na = X_test.copy()\n", "X_test_fill_na.fillna({\"Cabin\":\"cabin_missing\", \"Embarked\":\"embarked_missing\"}, inplace=True)\n", "\n", "# Filling in missing numeric data\n", "test_age_imputed = pd.DataFrame(\n", "    imputer.transform(X_test_fill_na[[\"Age\"]]),\n", "    index=X_test_fill_na.index,\n", "    columns=[\"Age\"]\n", ")\n", "X_test_fill_na[\"Age\"] = test_age_imputed\n", "\n", "# Handling categorical data\n", "X_test_categorical = X_test_fill_na[categorical_features].copy()\n", "X_test_ohe = pd.DataFrame(\n", "    ohe.transform(X_test_categorical),\n", "    index=X_test_categorical.index,\n", "    columns=np.hstack(ohe.categories_)\n", ")\n", "\n", "# Normalization\n", "X_test_numeric = X_test_fill_na[numeric_features].copy()\n", "X_test_scaled = pd.DataFrame(\n", "    scaler.transform(X_test_numeric),\n", "    index=X_test_numeric.index,\n", "    columns=X_test_numeric.columns\n", ")\n", "\n", "# Concatenating categorical and numeric data\n", "X_test_full = pd.concat([X_test_scaled, X_test_ohe], axis=1)\n", "X_test_full"]}, {"cell_type": "code", "execution_count": 18, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["0    175\n", "1     48\n", "Name: Residuals (counts), dtype: int64\n", "\n", "0    0.784753\n", "1    0.215247\n", "Name: Residuals (proportions), dtype: float64\n"]}], "source": ["y_hat_test = logreg.predict(X_test_full)\n", "\n", "test_residuals = np.abs(y_test - y_hat_test)\n", "print(pd.Series(test_residuals, name=\"Residuals (counts)\").value_counts())\n", "print()\n", "print(pd.Series(test_residuals, name=\"Residuals (proportions)\").value_counts(normalize=True))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["And still about 78% accurate on our test data!"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Summary\n", "\n", "In this lesson, you took a more complete look at a data science pipeline for logistic regression, splitting the data into training and test sets and using the model to make predictions. You'll practice this on your own in the upcoming lab before having a more detailed discussion of more nuanced methods for evaluating a classifier's performance."]}], "metadata": {"kernelspec": {"display_name": "Python (learn-env)", "language": "python", "name": "learn-env"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.5"}}, "nbformat": 4, "nbformat_minor": 2}